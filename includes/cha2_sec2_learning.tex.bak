\section{A review of imitation learning}
\label{cha2:sec2:learning}

This section give a brief introduction of robot imitation learning and then review its application in robot grasping and manipulation.

\subsection{Robot imitation learning}
Since the first study on robot imitation learning~\citep{friedrich1996robot}, this approach has become one of most popular research area in robotics. It is considered to be an designer-friendly approach to teach robot new tasks. The aim of imitation learning, referred as program by demonstration in some literatures, is to enable robot to learn new skills by observing human demonstrations and reuse these skill in similar tasks.

Demonstration based learning has been extensively studied~\cite{calinon2007learning,dillmann2004teaching,kulic2012incremental} as a promising approach to build robot intelligence.

\subsection{Robot learning grasping and manipulation }
\label{cha2:sec4:grasping-learning}

%[El-Khoury and Sahbani, 2010].
%\citet{bekiroglu2011assessing} integral the information of the object shape, approach vector, tactile data and joint configuration to estimate a grasp quality.

% Why need to use learning, benefit?
% ----- reduce complexity -----
As discussed in the Section~\ref{cha2:sec1:grasping}, conventional grasp and manipulation planning methods suffer from the curse of dimensionality.
Learning technique have been introduced to avoid the complexity of computing kinematical constraints guaranteeing stable grasps. Briefly speaking, robot grasping has two learning sources: imitation learning from human demonstration and learning from data collected from the simulation.
In imitation learning, some researchers use datagloves for human demonstration. The human hand configuration is then mapped to an artificial hand workspace and the joint angles~\citep{Fischer1998,ekvall2007learning}, or hand preshapes~\citep{Kyota2005, pelossof2004svm, Li07} are learnt. Some other researchers use stereoscopy to track the hand when a demonstrator is performing a grasp~\citep{hueser2006learning} or to match the hand shape to a database of grasp images~\citep{Romero2008}. For long term automatic learning, markerless methods to track human hand and arm movements in the approaching and grasp execution are studied~\citep{ekvall2007learning,do2009grasp}. These learning based approaches succeed in taking into account the hand kinematics and generate hand preshapes that are compatible with the object features. Human grasp postures are usually mapped to robot hand postures in fixed schemes, according to the shape of the object and the type of grasp human choose. The learn from simulation method get around this mapping step: it directly generate grasps with the robot hand mechanical constraints. For a given object shape and a robot hand, thousands of grasps are generated in the simulator and later used as training data. \citet{pelossof2004svm} use a discriminative model Support Vector Machine to learn the correlation between the grasp configuration and grasp quality while \citet{bidan2013grasp} use a generative model Gaussian Mixture Model to learn the distribution of force closure grasps. Both models are used to generate new grasps. Grasp training data can also be generated in a real robot platform rather than simulator~\citep{herzog2014learning}. However this method is much more time consuming and hence it focus on finding a way to maximize the use of the grasping experience, i.e. generalizing grasping strategies to novel objects.

To further reduce the complexity of grasping problem, modular approaches are used. This will be discussed in the Section~\ref{cha2:sec5}.

% ----- uncertainty -----
Besides reducing the complexity of grasping problem, learning approaches are also used to tackle those common problems appear in human environment: uncertainty and noise in perception data, novel objects and unforeseeable situations. \citet{ekvall2007learning,stulp2011learning} study human grasp motion and try to learn how human choose the approach vector that is robust to pose uncertainty. With the same principle, the human grasp postures are studied and mapped to robot hands in order to grasp objects of which the pose is not estimated with high confidence~\citep{tegin2009demonstration}. With the recent advance of tactile sensing technology, many attempt to include the tactile sensory data in assessing the grasp stability. By estimating the grasp stability after the grasp execution, failure further actions on the object can be avoided. \citet{bekiroglu2011assessing} integrate the information of the object shape primitive, approach vector, tactile data and hand joint configuration to estimate a grasp quality.
In the later work, contact point locations are also taken into account~\citep{dang2012learning,dang2014stable}. The support vector machine (SVM) is the most used model in this task.

% ------ novel object ------
The tactile feedback based methods are ``robot-centric'', i.e. they do not rely on the predefined object shape. Hence these methods can be easily applied to estimate grasp quality for novel objects. To generate grasps for novel objects, the mechanisms of both human perception and action are studied. \citet{detry2009learning} study the human Early-Cognitive-Vision (ECV) and use it as a feature to associate with grasps. The ECV feature includes colour and edge information and hence can be used to generate grasps for novel objects.
\citet{el2007learning} try to imitate human mechanism of representing objects and segment objects to a set of superquadric shape primitives. The mechanism of human choosing the grasp component is then learnt by a Neural Network~\citep{el2010new}.



% ----- fast adapt -----
Human environment is dynamics and full of perturbations. These perturbations can not be foreseen and can only be handled when happen. Learning approach is also used here to provide methods for quick adaptation. Methods are proposed to simplify the generation of grasp such that moving object can be caught~\citep{harada2008fast,kim2012,bidan2013grasp}
Beside using visual features, tactile sensors can provide additional useful information which is not accessible by vision. Many methods for quick adaption to the actual contact conditions are proposed~\citep{hsiao2010contact,hsiao2011robust,kazemi2012robust,sauser2011iterative,li2014learning}.




% --- Manipulation ---
%%% Compare to analytical solution: more robust, but not guarantee
%%The learning approaches generate give precise contact point locations that guarantee grasp stability. Instead, most of them generate a grasp by less specific specifications such as the approaching vector and pre-grasp postures.
%%At the other hand, these learning approaches usually rely on statistical models. Therefor these approaches do not provide guarantee of the performance of the grasp, even if the plan is execute perfectly. The stability of the planned grasps can only be evaluated after execution. However, for the same reason they tolerate a certain amount of noise and are more robust to errors. Hence, these methods are more suited to human dominate environments.
%%
%%Demonstration based learning has been extensively studied~\citep{calinon2007learning,dillmann2004teaching,kulic2012incremental} as a promising approach to build robot intelligence. %It is essential for the tasks that analytical expression of the system is hard to derive.
%%Learning manipulation tasks is one of the main application of this approach. The physical properties of a manipulation task is hard to express analytically, and as a result the control strategy is hard to derive. Modeling expert's demonstration of strategies has been used as an alternative to the analytical solution.
%%
%%Two major forms of demonstration are used in teaching manipulation tasks: kinematics teaching and tele-operation. In kinesthetic teaching, human directly contact with the robot and guide their movements to accomplish a task~\citep{korkinof2013online,pais2014encoding,pastor2011skill,Miao2014}. The trajectory of movements and contact force are recorded by the robot sensors.
%%% ===== Why not kinematics approach? =====
%%This method is simple and effective but limited in the number of controllable end effectors. While a manipulation task usually involves multifinger movement, a human can kinematically operate one finger with each hand and hence two fingers simultaneously at most. To control multi-finger hands, some researchers use tele-operation~\citep{bernardino2013precision,kondo2008recognition,Fischer98}. This usually relies on data gloves and motion capture system to sense human hand-arm motions. The human motion is mapped to robots to generate motions and interact with the environment. In fine manipulation tasks, the robot platforms are usually restricted to anthropomorphic hands for better mapping. All of these methods provide no direct force feedback to the human demonstrator during manipulation.
%%
%%In some studies, the human demonstrate manipulation tasks with their own bodies~\citep{asfour2008imitation}. With direct interaction with the object the human demonstrator is able to perform the task most naturally and with a more delicate control strategy. The task information captured from these human demonstrations needs to be transferred to robots. Various mapping methods have been proposed~\citep{hueser2006learning,asfour2008imitation,do2011towards,}, while human correction~\citep{calinon2007incremental,sauser2011iterative,romano2011human} and self-correction via learning~\citep{bidan2013robio} are proposed as alternative solutions. In general, how to effectively transfer human skills to robots skill remains a challenge.



%machine learning techniques  to the grasping
%problem. Some researchers use datagloves, map human hand to artificial hand workspace and learn the
%different joint angles~\cite{Fischer98,Ekvall07}, or hand
%preshapes~\cite{Kyota05, Pelossof04, Li07}  in order to perform a grasp. Others use
%stereoscopy to track the demonstrator's hand performing a
%grasp~\cite{Hueser06} or try to recognize its hand shape from a
%database of grasp images~\cite{Romero08}.
%However they focus on different problems, such as telemanipulation~\cite{Fischer98} and human hand tracking~\cite{Hueser06}, rather than real time unattended grasping.
%Other group of researches concentrate on generating a list of grasps for one object~\citep{Kyota05, Pelossof04, Li07, saut2011efficient}.

