\section{A review of modular approaches}
\label{cha2:sec3}
%\label{cha2:sec3:modular}
This section first briefly reviews the modular approaches studied in cognitive science and control theory, and then concentrates on modular approaches in robotics.

\subsection{Modular approaches in cognitive science}
\label{cha2:sec3:cognitive}
%\label{cha2:sec3:modular:ai}

% TODO: Modular approach in cognitive science (artificial intelligent and neuroscience), control and robotics
%It has also been shown to be an effective architecture of building intelligent systems~\cite{bryson2004modular,BrysonMcG12}.
% MOSAIC
One typical hypothesis of a modular model in motor control is MOSAIC: the Modular Selection and Identification of Control. It is a paradigm of multiple module control, where each module is composed of a forward model and an inverse model. The forward models are responsible for estimating the task context in real time, and the inverse models are used to generate appropriate motor commands for the context. The inverse models are weighted by the accuracy of the estimations of their corresponding forward models. The final motor command is the linear combination of the commands factored by their weights.

\textcolor{red}{TO BE EXTENDED}

\subsection{Modular approaches in control}
\label{cha2:sec3:control}
%\label{cha2:sec3:modular:control}
%Aim: MMAC is good, useful. Discussed for long. Hard to decide -> learning.

% Adaptive control
The use of modular approaches in control theory is different from that used in AI. As discussed above, in the discipline of AI, modularity is needed when building a large complex versatile system. In the discipline of control theory, on the other hand, modular approaches are used to handle the adaptive control problem, which is usually referred to as multiple model adaptive control (MMAC).
\textcolor{red}{I'm not sure that this last sentence explains what the differences really are between a modular approach in AI and a modular approach in control theory}
%It is method to handel .... problems in adaptive control.
Adaptive control is a control method where the controller changes itself to adapt to the changes in the control condition.
A commonly used example is where the controller of an aeroplane adapts to a reduction in the weight of the jet fuel.
Conventional adaptive control methods rely on state estimation. The controller tries to estimate the changes of the system dynamics and then modulates its control parameters to adapt to the changes. For frequently changing environments, however, the period of modulation of the control parameters may cause a transient error, where strong fluctuations can downgrade the performance and damage the hardware. MMAC is used to reduce the transient error by conducting a fast adaption. A MMAC system is usually composed of several different controllers, each particularly designed for one control condition. During the control process, the environment is monitored in real time and one or more controllers suitable for this environment are activated to generate the control command. When the system encounters a sudden change, it will adapt to it by activating another set of controllers. It does not need to re-optimise the control parameters and hence the transient error is reduced.

MMAC dates back to the 1970s. \citet{athans1977stochastic} use multiple Kalman filters in controlling equilibrium flight, to handle sensor errors and to reconstruct the state variables in different flight conditions. The final adaptive control signal is computed by the linear combination of the control signal generated by each model, weighted by the associated probability. Later, a switching MMAC is proposed and its stability is studied~\citep{fu1986adaptive}.
%Switching was first introduced by Martennson1986
%Morse 1993 study stability
\citet{narendra1994improving} use MMAC to improve the performance of the controller in multiple environments, particularly to reduce the transient error that is caused during the transition of the control parameters from one set of optimal values to another. They later use neural networks to build models for the non linear system~\citep{narendra1995adaptation,narendra1997adaptive}. This controller is implemented in a robot manipulator to follow a predefined trajectory and shows improved performance compared to single model control.

To apply MMAC to a practical control problem, the first step is to design how many modules to use and how to decompose the problem space. For linear plants, this problem is addressed by \citet{anderson2000multiple}. They use the concept of Vinnicombe distance 
\textcolor{red}{need reference to Vinnicombe distance}
to decompose the space. Firstly, an initial random starting point is chosen, where a controller is determined. The controller finds its boundary in the neighborhood where its control is acceptably accurate.
\textcolor{red}{do you mean 'unacceptably', or 'still acceptably'? What defines the boundary condition?}
At the boundary, a new starting point is chosen and a new controller is determined. This process continues until the whole space is covered. Based on this method, \citet{lourenco2006learning} 
\textcolor{red}{citation missing}
propose an approach to recognize the new condition and learn new controls online to adapt. These methods, however, only perform well for learn plants.
\textcolor{red}{learn plants? what?}
How to apply MMAC in nonlinear systems remains a challenge.

In robot control, MMAC has many applications for conducting a task in frequently varying environments. These changing environments can be caused by many factors, such as object interactions. Works on this topic include \citet{petkos2006learning} learning multiple inverse models for controlling robots to follow a trajectory with different workloads on the arm; \citet{nakanishi2013spatio} proposing a time-based switching method for robot systems with variable stiffness actuation to handle the different phases of interaction with the environment; the ``eMOSAIC''~\citep{sugimoto2012emosaic} to bring the MOSAIC from simulation to real robot control. In the last work, the performance of MOSAIC under large observation noise is improved by using an optimal control technique. The method is implemented on the 51 DOF humanoid robot CB-i for a squatting task and a carrying load task. As far as we know, this is the first MMAC implementation for a real robot.

Despite the remarkable theoretical accomplishments and many successful applications of MMAC, its application in controlling service robots is not flourishing. Partly this is because robotics always involves non linear control problems, for which the MMAC has not a principle solution.
\textcolor{red}{need to use another phrase here instead of 'not a principle solution'. Do you mean that MMAC is not the ideal solution for non linear control problems?} 
Also, a MMAC controller itself is difficult to design. Control problems in robotics are highly task specific and the service robots are expected to handle a huge number of tasks.
\textcolor{red}{I have changed 'amount' to 'number' in the sentence above. If the thing we are talking about is continuous we use amount (like for milk), but if it is discrete (like biscuits) then we use number as above. End Lesson :)}
 Hand designing a MMAC for these tasks is not cost effective. %Some of the tasks may needed to be end-user defined, that necessitates a simple user-friendly design scheme.

%But how to modularize is still a problem.
%Anderson 2000 how to decide number of modules for linear plan:
%SMMAC decide when to learn a new module online.
%Predictive control with infinite number of modules.

%Robot:
%Narendra 1995 study robot manipulator
%Sethu with multip phases.
%eMOSAIC
%2012_Design of a grasp force adaptive control system with tactile and slip
%
%
%To handle this problem, the multiple model control is introduced in the 1990's ~\citep{narendra1994improving} and later developed~\citep{narendra1995adaptation,narendra1997adaptive}. This approach is inspired by the local expert model introduced by~\citet{jacobs1991adaptive}. This work propose to use local controllers for different subspaces of the system to improve the control performance.
% Talk about basic idea.  1995 in robot manipulator.

% Talk about developement, 1995 in robot manipulator?

% Read review of adaptive control

%Vinnicombe distance to find number of module?

% Vijarkumar's papers?

% multiple control with mixing. different from local expert?


\subsection{Modular approaches in robotics}
\label{cha2:sec3:robotics}
%\label{cha2:sec3:modular:robotics}
In the previous two sections we list a few applications of the modular approach in robotics from the AI and control prospectives. Modular approaches in robotics go further. In recent years, there have been many studies in the modular approach, especially in robot motion planning, grasp planning and manipulation planning. This is mainly due to the trend to try to move robots from the industrial controlled environment to the human dominated environment, where the robots have to handle dynamic and complex situations. In this section, we will give an overview of modular approaches to motion planning. Applications in grasp planning and manipulation will be reviewed in detail in Section~\ref{cha2:sec5:grasping-modular}.
\textcolor{red}{cross reference missing}
Modularities in robotics always refer to ``primitives'', such as ``object shape primitives'', ``motion primitives'' and ``manipulation primitives''. Among these, the most extensively studied area is motion primitives.
To build a versatile service robot that can work in a human dominated environment and assist a human, high level behaviour planning is required. This means robots need to be equipped with the ability to plan a sequence of movements that fulfil a commanded task, such as ``clean the table'' and ``put the food into the fridge''. The conventional method of motion planning is to search in a high dimensional space formed by the numerous degree of freedoms of the robot. The number of possible solutions to accomplish a task is therefore nearly infinite.

This redundancy is useful. In reality various constraints, such as avoiding obstacles, may be added to the task. Due to the redundancy, we are able to find feasible solutions under multiple task constraints. However, this redundancy also makes planning difficult as the search space is extremely large. One common approach is to carry out optimization for the task with constraints that are mathematically equivalent to the task constraints.
\textcolor{red}{you need to check the last sentence as I have changed it to read properly, but the sense may now be wrong}
The drawback of this optimization approach is that defining a proper cost function and proper constraints for the task is not easy. This requires the robot use to process a certain amount of knowledge in mathematics and mechanism, as well as a deep understanding of the task.
\textcolor{red}{rewrite last sentence as I'm not sure what you are trying to say here}
As an alternative, modular approaches can be used to reduce the search space, without discarding good solutions. To this end, the concept of the motion primitive is introduced into robotics. This is a concept from neuroscience research. Neuroscientists have found evidence to suggest that the vertebrate motor system generates motions by combining a small number of motor primitives~\citep{mussa1994linear,mussa1999modular,bizzi2008combining,grillner2011control}. These show the modularized mechanism running in brains: each motor primitive is one module, the combination of many modules generates the complex behaviour.

This idea inspired roboticists to develop simple motion primitives and use them as substrates to develop complex behaviours. In robot motion planning, motion primitives are defined as the most elementary motions, each of which serves one particular purpose. A common way to generate motion primitives is to extract them from human demonstrations: motion sequences demonstrated by humans are discretized to a sequence of motion primitives. Modularized by the motion primitives, the task planning problem is brought from a huge high dimensional search space to a finite discrete space.
They can be reused in other tasks as functional units. %This motion primitive approach has been studied in many literatures~\ref{}.
\textcolor{red}{I don't think you need this sentence. Its obvious.}

% ----- Model motion primitives -----
A great deal of research literature has discussed the use of motion primitives.
\textcolor{red}{Maybe you should cite some here}
Robot motion primitives are learned from humans. These approaches mainly focus on three problems, which are also the typical problems in a modular approach: how to model the motion primitives, how to extract motion primitives from a complex motion sequence and how to combine them to form a complex behaviour.

In studies of the first problem, many roboticists encode the motion primitives with statistical or analytical models, which can be modulated to some extent by varying the parameters according to the requirements of a certain task. The most used modeling methods for motion primitives are The Hidden Markov Model (HMM), mixture models such as the Gaussian Mixture Model (GMM) and the dynamical systems model represented by a set of non linear differential equations. HMM is used to encode temporal motions~\citep{inamura2004embodied,kulic2008incremental,takano2008integrating,lee2010incremental,bidan2013robio}. For time independent motions, \citet{gribovskaya2010learning,khansari2010imitation} use GMM to model multiple human demonstrations in the state space, while \citet{ijspeert2002movement,Ijspeert2003attractor,schaal2005learning,peters2008reinforcement} use nonlinear differential equations to capture an observed behaviour in an attractor landscape. The later is referred as the Dynamical Movement Primitives (DMP), of which the design principle and roadmap is reviewed in \citep{ijspeert2013dynamical}.

% ----- Segmentation -----
Many of the algorithms mentioned above obtain the motion primitives from manual segmentation of motions. However, it is still not clear to us how many motion primitives we need to compose all the human daily behaviours and what these primitives should be. To obtain these primitives, demonstrating all primitives or manually extracting motion primitives from demonstrations is not practical. Even if a library of motion primitives existed, to learn a complex behaviour from human demonstration, a robot still needs to recover the motion primitives from demonstrated motion sequences. Hence, a general automatic mechanism to extract motion primitives is required.

To this end, segmentation of a motion sequence \citep{takano2006humanoid,Pais2013ID879} and clustering of data \citep{kulic2009online,kulic2012incremental} are the most used techniques. These approaches usually rely on a carefully chosen threshold to decide when to segment and stop clustering. A method is to set boundaries on the kinematic variables such as the velocity: \citet{fod2002automated} segment a sequence when a Zero Velocity Crossing (ZVC) is observed. \citet{takano2006humanoid} perform the segmentation according to the correlation among short motions. They first divide the sequence to a set of short notes. When a new motion is demonstrated, they segment it at the moment that the difference between the predicted next note and actual observed one is larger than a threshold. \citet{kulic2008incremental} use a hierarchical clustering method to extract primitives from human motion sequences. Different cut off parameters are tested to evaluate the trade off effect between facilitating quick group formation and introducing misclassification. \citet{Pais2013ID879} extract the primitives according to the variances of the motions in a few demonstrations for a same task. Many other approaches have been proposed to extract motion primitives according to their task requirements. All of these approaches aim to extract a set of motion primitives that are independent functional units and generalized enough to be reused in many tasks. With these pre-defined motion primitives, online recovery of a sequence of motion primitives is feasible. With the presumption of an existence of a motion primitives library we can reduce the segmentation problem to an online motion recognition problem~\citet{meier2011movement}.
%Approaches in this trend mainly have two directions: algorithms with prior knowledge of the motion primitives and and unsupervised algorithms that do not require prior information. The former direction assume an existence of

% ----- Combine -----
The intention of modelling motion primitives is to use them to help with the motion planning problem. According to the task, the use of the motion primitives can be in the form of selecting, mixing or sequencing. The selecting and mixing are for adaptive behaviour: the robot needs to select one or mix a few motion primitives according to the current task context such that it can finish the task.
%Hence another important trend of study is using primitives to form useful behaviors.
%The ``combination'' has two main forms: selecting and mixing.
Selection can be decided by a pre-learned correlation between the primitives and the task contexts: the highest correlated primitive with the current task context is the one to choose~\citep{takano2006primitive}. On the top of this, \citet{daniel2013learning} use Relative Entropy Policy Search (REPS) to optimize the joint state-action distribution and hence choose the optimal set of parameters for the primitive.
Some others choose the primitive that can result in a system state closest to the desired next system state~\citep{hauser2008using}. A similar idea is used in the mixing method, where more than one motion primitive can be activated at the same time. The weight of each motion primitive is computed to make sure the resulting motion can bring the system to the desired state~\citep{bidan2013robio,sugimoto2012emosaic}. From the human robot interaction perspective, the robot should be able to understand human verbal commands and plan the action. \citet{takano2008integrating} propose a method to associate morpheme words with motion primitives. This potentially enables the robots to understand human commands and plan motion by parsing the sentence.




\subsection{Grasping and manipulation by modular approaches}
\label{cha2:sec3:grasping-modular}
%\label{cha2:sec5:grasping-modular}

Modular approaches in robot grasping and manipulation to reduce the problem complexity. Modularization in grasping and manipulation are mainly done in two approaches: modularize by perception and modularize by action. Perceptual modules are mainly used in planning, while action modules are mainly used in execution.

\paragraph{Modularize by perception}
~\\
The first step of making a plan of grasping and manipulation is observing the object. Most of grasp stability analysis are done based on the shape of an object. In human dominated environment, the possible shapes of objects to grasp and manipulate is infinite. Conventional methods to model these object are only effective in convex models. For highly non-convex shapes, local vision features such as edges and colors are used to generate grasping plans at the local areas. To generate grasp for the whole object, \citet{miller2003automatic} propose a modular approach, i.e. planning grasps by shape primitives. The key idea is to approximate a complex object, e.g. non-convex shape, to a set of shape primitives such as boxes, cylinders and spheres. Planning on these shape primitives is relatively easier or pre-trained. Therefore the complex planning problem is tamed to a set of simple problems. According to different purposes, different shape primitives are proposed. \citet{miller2003automatic} use four primitives including box, cone, cylinder and sphere; \citet{huebner2008minimum} use minimum bounding box to decompose an object and \citet{el2010new} use superquadric as the shape primitive. These methods are based on the complete object point clouds, which may not be fully accessible in the real scenario. Methods to split objects to shape primitives and detect primitives parts are proposed, which mainly exploit the techniques in graphics such as the RANdom SAmple Consensus (RANSAC)~\citep{garcia2009fitting,gallardo2011detection}.
\citet{faria2012extracting} use multiple sensors to track human hand trajectory and tactile data, and hence extract motion primitives and contact primitives from the demonstration. These information is then merged to form a object probabilistic volumetric model, which is decomposed to multiple superquadrics.

\paragraph{Modularize by action}
~\\
The motion primitive concept is also introduced to grasping and manipulation. These differ from the reaching movement primitives discussed in the previous Section~\ref{cha2:sec3:modular:robotics}, where the goal is to reach the targeted points. The grasping and manipulation motion primitives are more task-oriented, i.e. each primitive is associated with a specific impact on the environment, such as getting contact with the object and pushing the object. Therefore in the literature these primitives are sometimes referred to as ``task primitives''. Because of the variety of tasks and their complexity, these task primitives are usually manually defined. Transitions between them are usually decided by contact events that indicate the impacts on the environment~\citep{morrow1997manipulation}. \citet{michelman1994forming} propose the representation of the relationship between task primitives by a finite state machine. \citet{kazemi2012robust} define three task primitives for force compliant grasping of small objects from a table top. The Dynamical Movement Primitives (DMP) mentioned previously, which model desired motion by an attractor landscape, is extended to deal with various problems when executing a grasp. The combination of the DMP and the Early Cognitive Vision Descriptor (ECVD) for grasp planning enable a robot to plan the path of  approach of the hand and the finger to avoid premature contact between finger and object~\citep{kroemer2011grasping}. Taking the object poses distribution into account, a new optimization method of the DMP is proposed to find an approach trajectory that produces robust grasps with object pose uncertainty~\citep{stulp2011learning}. Later simplify version of DMP is used to learn movement goal and hence can quickly change the end point location to adapt to the object shape~\citep{stulp2011learning,stulp2012reinforcement}.
\textcolor{red}{cannot fix last sentence as don't know what you mean - sorry}

A number of frameworks are proposed to model and organize the task primitives. \citet{laaksonen2010embodiment,felip2013manipulation} propose a hierarchical framework to solve the embodiment problem of sharing experience among different robot platforms. This is done by defining task primitives in an abstract layer and an embodiment layer.
\textcolor{red}{defined in two layers then? Should it say ...in both an abstract layer and an embodiment layer}
The former can be translated to the latter. This enables the robot to plan tasks with the higher level abstract primitives, and execute them with the embodiment specific task primitives. To facilitate manipulation motion planning, \citet{barry2013manipulation} use a Rapidly exploring Random Tree (RRT) to sequence motion primitives. \citet{detry2013generalizing} modularize a grasp planning task by two constraints: gripper constraints and task constraints. While the former modules handle grasp stability, the latter modules select grasps from the task requirements.

Besides task-specific motion primitives, modular approaches are also used to tame the complex grasp planning problem. The concept of ``hand synergies'' for example, is a modular approach originating in neurophysiological studies~\citep{santello1998postural,santello2000force}. In this field of study, roboticists try to understand how the human central neural system (CNS) simplifies the grasping strategy and how to mimic this mechanism in robot systems. This concept is used in grip force control \citep{gabiccini2011role} as well as grasp planning \citep{gioioso2013mapping}. Similar to this idea, robot ``Eigen grasps'' have been proposed to study the modularity in robot embodiment. Instead of directly searching for good grasps in the high dimensional configuration space of robotic hands, this space can be reduced by generating a set of grasp starting positions, hand preshapes~\cite{miller2003automatic} or eigengrasps~\cite{Ciocarlie2009} that can then be tested on the object model. Such approaches reduce the dimensionality of the hand configuration space, but doing so implies a corresponding reduction in the accessible hand postures.



%This involve not only the studies of the redundancy in human hand mobility but also the redundancy in human cutaneous and kinaesthetic perception. With the recent rapid development of tactile sensors, robots are equipped with more delicate tactile perception. How collect sensation information from these tactile receptors is also a hot topic in robot synergies. In once word, the study of robot sensorimotor synergies aim to find out the modularity in human muscles, joints, fingers, receptors so as to enable robot working in complex and dynamic system.
% Eigen grasp

%TODO: Problem need to solve in modular approach


%In robot grasping, modularity is also studied. In general, planning a grasp for a multifinger robot hand and a given object shape is a computational expansive task, especially for anthropomorphic robot hand with numerous number of joints. XXXXX~\ref{} proposed the concept of ``eigengrasp'' to simplify the grasp planning problem: three different preshapes of the hand are tested to grasp different objects. Approaching the object with a particular preshape until touching, the hand clutch around the object to form a grasp. XXXXX of objects are successfully grasped by one of the three preshapes. This modular approach reduce the complex grasp planning problem to a simple 3-class classification: one only need to classify with preshapes needs to be used for the target object and decide the approach direction.


