\section{A review of modular approaches}
\label{cha2:sec3}
%\label{cha2:sec3:modular}
This section first briefly reviews the modular approaches studied in cognitive science (including AI, neuroscience and psychology) and control theory, and then concentrates on modular approaches in robotics.

\subsection{Modular approaches in cognitive science}
\label{cha2:sec3:cognitive}
%\label{cha2:sec3:modular:ai}

% Since Fodor, debate of modularity continues
% massive modularity / minimum modularity... what are they for? solve what problem?
Beginning from the publication of Fodor's book \textit{The Modularity of Mind}~\citep{fodor1983modularity}, the debate on modularity in cognitive science has lasted for three decades. The principle of this view is that there exists a certain number of subsystems in the brain, each of which independently in charge of a certain function. Massive opponents argue against this view, along with many further developments of the modularity theory. Different from Fodor's believe that modularity acts in the low-level systems such as vision, some other researchers argue that the high-level systems of mind such as reasoning, judgement and decision making also have modularity~\citep{samuels2000massively,carruthers2006architecture}. This view, known as the ``massive modularity'', claims that human mind is a complex system and need to have massively modular organization. Debates of modularity last till tody as reviewed in \citet{barrett2006modularity} and we do not have an unified opinion of the mechanism of the brain. Despite this, none of these studies deny that modularity can help developing complex systems.

% neuroscience evidence for motor control
Studies and ideas of modularity is not confined to psychology. In AI, modular approach has been shown as an effective architecture of building intelligent systems~\citep{bryson2004modular,BrysonMcG12}. Neuronscientists also do researches on this topic. Many neuronscience evidences support the hypothesis of modularity in motor control, that the vertebrate motor system generate motions by combining a small number of motor primitives~\citep{mussa1994linear,mussa1999modular,bizzi2008combining,grillner2011control}. The combination of motion primitives generates complex behaviours.

% MOSAIC
Based on these neuronscience evidences, researchers propose modular models to explain human motor control mechanism. One typical hypothesis is MOSAIC: the MOdular Selection And Identification of Control. It is a paradigm of multiple module motor control, where each module is composed of a forward model and an inverse model. The forward models are responsible for estimating the task context in real time, and the inverse models are used to generate appropriate motor commands for the context. The inverse models are weighted by the accuracy of the estimations of their corresponding forward models. The final motor command is the linear combination of the commands factored by their weights. The work presents in Chapter~\ref{cha4} takes this paradigm and implement it to a robot. Details will be explain in that Chapter.



\subsection{Modular approaches in control}
\label{cha2:sec3:control}
%\label{cha2:sec3:modular:control}
%Aim: MMAC is good, useful. Discussed for long. Hard to design -> learning.

% MMAC
In control theory, modular approaches are mostly used to handle the adaptive control problem. In many literatures this is usually referred to as multiple model adaptive control (MMAC). Adaptive control is a method where the controller changes itself to adapt to the changes in the control condition. A commonly used example is where the controller of an aeroplane adapts to a reduction in the weight of the jet fuel. The concept of MMAC is as follow. There is a set of plants and multiple controllers. Any plant in this set can be satisfactorily controlled by at least on of the controllers. When the plant switch from one to another, i.e. the environmental condition or task context changes, the control system also switch from one set of controllers to another.

%Compare to others
Compare to other single controller methods, MMAC has the advantage of fast and stable adaption.
Conventional adaptive control methods rely on state estimation. The controller tries to estimate the changes of the system dynamics and then modulates its control parameters to adapt to the changes. For frequently changing environments, however, the period of modulation of the control parameters may cause a transient error, where strong fluctuations can downgrade the performance and damage the hardware. MMAC is used to reduce the transient error by conducting a fast adaption.

% paradigm of MMAC
A paradigm of a MMAC system is a system composed of several different controllers and a environment monitor. During the control process, the environment is monitored in real time and one or more controllers suitable for this environment are activated to generate the control command. When the environment suddenly changes, the monitoring signal will activate another set of controllers. It does not need to re-optimise the control parameters to adapt. Hence with MMAC the reaction time is shorten and the transient error is reduced.

% history
Literatures of MMAC date back to the 1970s. \citet{athans1977stochastic} use multiple Kalman filters in controlling equilibrium flight, to handle sensor errors in different flight conditions. The final adaptive control signal is computed by the linear combination of the control signal generated by each model, weighted by the associated probability. Later, a switching MMAC is proposed and its stability is proven by~\citet{fu1986adaptive}.
%Switching was first introduced by Martennson1986
%Morse 1993 study stability
\citet{narendra1994improving} use MMAC to improve the performance of the controller in multiple environments, particularly to reduce the transient error that is caused during the transition of the control parameters from one set of optimal values to another. They later use neural networks to build models for the non linear system~\citep{narendra1995adaptation,narendra1997adaptive}. This controller is implemented in a robot manipulator to follow a predefined trajectory and shows improved performance compared to single model control.

To apply MMAC to a practical control problem, the first step is to design how many modules to use and how to decompose the problem space. The previous mentioned methods do this manually. To automate this step, \citet{anderson2000multiple} propose a method for linear plants. They use the Vinnicombe distance~\citep{vinnicombe1993frequency} to span and decompose the space. Firstly, an initial random starting point is chosen, where a controller is determined. The controller finds its boundary in the neighborhood where it can control satisfactorily.
At the boundary, a new starting point is chosen and a new controller is determined. This process continues until the whole space is covered. Based on this method, \citet{lourenco2006learning} propose an approach to recognize the new condition and learn new controllers online to adapt. These methods, however, are only applicable for linear plants. How to apply MMAC in nonlinear systems remains a open question.

In robot control, MMAC has many applications for conducting a task in frequently varying environments. These changing environments can be caused by many factors, such as object interactions. Works on this topic include \citet{petkos2006learning} learning multiple inverse models for controlling robots to follow a trajectory with different workloads on the arm; \citet{nakanishi2013spatio} proposing a time-based switching method for robot systems with variable stiffness actuation to handle the different phases of interaction with the environment; the ``eMOSAIC''~\citep{sugimoto2012emosaic} to bring the MOSAIC from simulation to real robot control. In the last work, the performance of MOSAIC under large observation noise is improved by using an optimal control technique. The last method is implemented on the 51 DOF humanoid robot CB-i for a squatting task and a carrying load task. As far as we know, this is the first MMAC implementation for a real robot.

Despite the remarkable theoretical accomplishments and many successful applications of MMAC, its application in controlling service robots is not flourishing. One one hand, this is because robotics always involves non linear control problems, for which the modularization remains a open question.
On the other hand, a MMAC controller itself is difficult to design. Control problems in robotics are highly task specific and the service robots are expected to handle a huge number of tasks. Hand designing a MMAC for all tasks is not cost effective. %Some of the tasks may needed to be end-user defined, that necessitates a simple user-friendly design scheme.

%But how to modularize is still a problem.
%Anderson 2000 how to decide number of modules for linear plan:
%SMMAC decide when to learn a new module online.
%Predictive control with infinite number of modules.

%Robot:
%Narendra 1995 study robot manipulator
%Sethu with multip phases.
%eMOSAIC
%2012_Design of a grasp force adaptive control system with tactile and slip
%
%
%To handle this problem, the multiple model control is introduced in the 1990's ~\citep{narendra1994improving} and later developed~\citep{narendra1995adaptation,narendra1997adaptive}. This approach is inspired by the local expert model introduced by~\citet{jacobs1991adaptive}. This work propose to use local controllers for different subspaces of the system to improve the control performance.
% Talk about basic idea.  1995 in robot manipulator.

% Talk about developement, 1995 in robot manipulator?

% Read review of adaptive control

%Vinnicombe distance to find number of module?

% Vijarkumar's papers?

% multiple control with mixing. different from local expert?


\subsection{Modular approaches in robotics}
\label{cha2:sec3:robotics}
%\label{cha2:sec3:modular:robotics}
In recent years, there have been many studies in the modular approach in robotics, especially in motion planning, grasping and manipulation. This is mainly due to the trend to try to move robots from the industrial controlled environment to the human centered environment, where the robots have to handle dynamic and complex situations. In this section, we will give an overview of modular approaches to motion planning. Applications in grasp planning and manipulation will be reviewed in detail in the next section.

Modularities in robotics always refer to ``primitives'', such as ``motion primitives'', ``grasp primitives'', ``shape primitives'' and ``manipulation primitives''. Among these, the most extensively studied area is motion primitives.

% need of segmentation
To build a versatile service robot that can work in a human centered environment and assist a human, high level behaviour planning is required. This means robots need to be equipped with the ability to plan a sequence of movements that fulfil a commanded task, such as ``passing me the box'' and ``open the door''.

The conventional method of motion planning is to search in a high dimensional space formed by the numerous degree of freedoms of the robot. The number of possible solutions to accomplish a task is therefore nearly infinite.

% redundancy
This redundancy is useful. In reality, additional constraints such as avoiding obstacles and robot joint limit may be added to a task. Due to the redundancy, we are able to find feasible solutions under multiple task constraints. However, this redundancy also makes planning difficult as it makes the search space extremely large. One common solution of planning is to carry out optimization for the robot motion with constraints that are mathematically equivalent to the task constraints.
The drawback of this optimization approach is that defining a proper cost function and proper constraints for the task is not easy. This requires a certain amount of knowledge in mathematics and mechanics, as well as a deep understanding of the task.

As an alternative, modular approaches can be used to reduce the search space, without discarding good solutions. To this end, the concept of the motion primitive is introduced into robotics.
This concept from neuroscience studies, as reviewed in Section~\ref{cha2:sec3:cognitive}, inspired roboticists to develop simple motion primitives and use them as substrates to form complex behaviours. Here motion primitives are defined as the most elementary motions, each of which serves one particular purpose such as reaching a target point. Modularized as a set of motion primitives, the motion planning problem is brought from a huge high dimensional search space to a finite low dimensional space.


%They can be reused in other tasks as functional units. %This motion primitive approach has been studied in many literatures~\ref{}.


% ----- Model motion primitives -----
%A great deal of research literature has discussed the use of motion primitives.
%Robot motion primitives are learned from humans.
Motion primitive studies mainly focus on three problems, which are also the typical problems in a modular approach: how to model the motion primitives, how to extract motion primitives from a complex motion sequence and how to combine them to form a complex behaviour.


In studies of the first problem, many roboticists encode the motion primitives with statistical or analytical models, which can be modulated to some extent by varying the parameters according to the requirements of a certain task. The most used modeling methods for motion primitives are The Hidden Markov Model (HMM), mixture models such as the Gaussian Mixture Model (GMM) and the dynamical systems model represented by a set of non linear differential equations. HMM is used to encode temporal motions~\citep{inamura2004embodied,kulic2008incremental,takano2008integrating,lee2010incremental,bidan2013robio}. For time independent motions, \citet{gribovskaya2010learning,khansari2010imitation} use GMM to model multiple human demonstrations in the state space, while \citet{ijspeert2002movement,Ijspeert2003attractor,schaal2005learning,peters2008reinforcement} use nonlinear differential equations to capture an observed behaviour in an attractor landscape. The later is referred as the Dynamical Movement Primitives (DMP), of which the design principle and roadmap is reviewed in \citep{ijspeert2013dynamical}.

% ----- Segmentation -----
The pervasive way to generate motion primitives is to extract them from human demonstrations. Motion sequences demonstrated by humans are discretized to a sequence of motion primitives.
Many of the algorithms mentioned above obtain the motion primitives from manual segmentation of motions. However, it is still not clear to us how many motion primitives we need to compose all the human daily behaviours and what these primitives should be. To obtain these primitives, demonstrating all primitives or manually extracting motion primitives from demonstrations is not practical. Even if a library of motion primitives existed, to learn a complex behaviour from human demonstration, a robot still needs to recover the motion primitives from demonstrated motion sequences. Hence, a general automatic mechanism to extract motion primitives is required.

To this end, segmentation of a motion sequence \citep{takano2006humanoid,Pais2013ID879} and clustering of data \citep{kulic2009online,kulic2012incremental} are the most used techniques. These approaches usually rely on a carefully chosen threshold to decide when to segment and stop clustering. A method is to set boundaries on the kinematic variables such as the velocity: \citet{fod2002automated} segment a sequence when a Zero Velocity Crossing (ZVC) is observed. \citet{takano2006humanoid} perform the segmentation according to the correlation among short motions. They first divide the sequence to a set of short notes. When a new motion is demonstrated, they segment it at the moment that the difference between the predicted next note and actual observed one is larger than a threshold. \citet{kulic2008incremental} use a hierarchical clustering method to extract primitives from human motion sequences. Different cut off parameters are tested to evaluate the trade off effect between facilitating quick group formation and introducing misclassification. \citet{Pais2013ID879} extract the primitives according to the variances of the motions in a few demonstrations for a same task. Many other approaches have been proposed to extract motion primitives according to their task requirements. All of these approaches aim to extract a set of motion primitives that are independent functional units and generalized enough to be reused in many tasks. With these pre-defined motion primitives, online recovery of a sequence of motion primitives is feasible. With the presumption of an existence of a motion primitives library we can reduce the segmentation problem to an online motion recognition problem~\citet{meier2011movement}.
%Approaches in this trend mainly have two directions: algorithms with prior knowledge of the motion primitives and and unsupervised algorithms that do not require prior information. The former direction assume an existence of

% ----- Combine -----
The intention of modelling motion primitives is to use them to help with the motion planning problem. According to the task, the use of the motion primitives can be in the form of selecting, mixing or sequencing. The selecting and mixing are for adaptive behaviour: the robot needs to select one or mix a few motion primitives according to the current task context such that it can finish the task.
%Hence another important trend of study is using primitives to form useful behaviors.
%The ``combination'' has two main forms: selecting and mixing.
Selection can be decided by a pre-learned correlation between the primitives and the task contexts: the highest correlated primitive with the current task context is the one to choose~\citep{takano2006primitive}. On the top of this, \citet{daniel2013learning} use Relative Entropy Policy Search (REPS) to optimize the joint state-action distribution and hence choose the optimal set of parameters for the primitive.
Some others choose the primitive that can result in a system state closest to the desired next system state~\citep{hauser2008using}. A similar idea is used in the mixing method, where more than one motion primitive can be activated at the same time. The weight of each motion primitive is computed to make sure the resulting motion can bring the system to the desired state~\citep{bidan2013robio,sugimoto2012emosaic}. From the human robot interaction perspective, the robot should be able to understand human verbal commands and plan the action. \citet{takano2008integrating} propose a method to associate morpheme words with motion primitives. This potentially enables the robots to understand human commands and plan motion by parsing the sentence.




\subsection{Grasping and manipulation by modular approaches}
\label{cha2:sec3:grasping-modular}
%\label{cha2:sec5:grasping-modular}

Modular approaches in robot grasping and manipulation to reduce the problem complexity. Modularization in grasping and manipulation are mainly done in two approaches: modularize by perception and modularize by action. Perceptual modules are mainly used in planning, while action modules are mainly used in execution.

\paragraph{Modularize by perception}
~\\
The first step of making a plan of grasping and manipulation is observing the object. Most of grasp stability analysis are done based on the shape of an object. In human centered environment, the possible shapes of objects to grasp and manipulate is infinite. Conventional methods to model these object are only effective in convex models. For highly non-convex shapes, local vision features such as edges and colors are used to generate grasping plans at the local areas. To generate grasp for the whole object, \citet{miller2003automatic} propose a modular approach, i.e. planning grasps by shape primitives. The key idea is to approximate a complex object, e.g. non-convex shape, to a set of shape primitives such as boxes, cylinders and spheres. Planning on these shape primitives is relatively easier or pre-trained. Therefore the complex planning problem is tamed to a set of simple problems. According to different purposes, different shape primitives are proposed. \citet{miller2003automatic} use four primitives including box, cone, cylinder and sphere; \citet{huebner2008minimum} use minimum bounding box to decompose an object and \citet{el2010new} use superquadric as the shape primitive. These methods are based on the complete object point clouds, which may not be fully accessible in the real scenario. Methods to split objects to shape primitives and detect primitives parts are proposed, which mainly exploit the techniques in graphics such as the RANdom SAmple Consensus (RANSAC)~\citep{garcia2009fitting,gallardo2011detection}.
\citet{faria2012extracting} use multiple sensors to track human hand trajectory and tactile data, and hence extract motion primitives and contact primitives from the demonstration. These information is then merged to form a object probabilistic volumetric model, which is decomposed to multiple superquadrics.

\paragraph{Modularize by action}
~\\
The motion primitive concept is also introduced to grasping and manipulation. These differ from the reaching movement primitives discussed in the previous Section~\ref{cha2:sec3:robotics}, where the goal is to reach the targeted points. The grasping and manipulation motion primitives are more task-oriented, i.e. each primitive is associated with a specific impact on the environment, such as getting contact with the object and pushing the object. Therefore in the literature these primitives are sometimes referred to as ``task primitives''. Because of the variety of tasks and their complexity, these task primitives are usually manually defined. Transitions between them are usually decided by contact events that indicate the impacts on the environment~\citep{morrow1997manipulation}. \citet{michelman1994forming} propose the representation of the relationship between task primitives by a finite state machine. \citet{kazemi2012robust} define three task primitives for force compliant grasping of small objects from a table top. The Dynamical Movement Primitives (DMP) mentioned previously, which model desired motion by an attractor landscape, is extended to deal with various problems when executing a grasp. The combination of the DMP and the Early Cognitive Vision Descriptor (ECVD) for grasp planning enable a robot to plan the path of  approach of the hand and the finger to avoid premature contact between finger and object~\citep{kroemer2011grasping}. Taking the object poses distribution into account, a new optimization method of the DMP is proposed to find an approach trajectory that produces robust grasps with object pose uncertainty~\citep{stulp2011learning}. In a later work, the uncertainty of object shape is also taken into account. The DMP can change the end point of the movement according to the shape of the object~\citep{stulp2012reinforcement}.

A number of frameworks are proposed to model and organize the task primitives. \citet{laaksonen2010embodiment,felip2013manipulation} propose a hierarchical framework to solve the embodiment problem of sharing experience among different robot platforms. The task primitives is defined in an abstract layer and an embodiment layer.
The former can be translated to the latter. This enables the robot to plan tasks with the higher level abstract primitives, and execute them with the embodiment specific task primitives. To facilitate manipulation motion planning, \citet{barry2013manipulation} use a Rapidly exploring Random Tree (RRT) to sequence motion primitives. \citet{detry2013generalizing} modularize a grasp planning task by two constraints: gripper constraints and task constraints. While the former modules handle grasp stability, the latter modules select grasps from the task requirements.

Besides task-specific motion primitives, modular approaches are also used to tame the complex grasp planning problem. The concept of ``hand synergies'' for example, is a modular approach originating in neurophysiological studies~\citep{santello1998postural,santello2000force}. In this field of study, roboticists try to understand how the human central neural system (CNS) simplifies the grasping strategy and how to mimic this mechanism in robot systems. This concept is used in grip force control \citep{gabiccini2011role} as well as grasp planning \citep{gioioso2013mapping}. Similar to this idea, robot ``Eigen grasps'' have been proposed to study the modularity in robot embodiment. Instead of directly searching for good grasps in the high dimensional configuration space of robotic hands, this space can be reduced by generating a set of grasp starting positions, hand preshapes~\cite{miller2003automatic} or eigengrasps~\cite{Ciocarlie2009} that can then be tested on the object model. Such approaches reduce the dimensionality of the hand configuration space, but doing so implies a corresponding reduction in the accessible hand postures.



%This involve not only the studies of the redundancy in human hand mobility but also the redundancy in human cutaneous and kinaesthetic perception. With the recent rapid development of tactile sensors, robots are equipped with more delicate tactile perception. How collect sensation information from these tactile receptors is also a hot topic in robot synergies. In once word, the study of robot sensorimotor synergies aim to find out the modularity in human muscles, joints, fingers, receptors so as to enable robot working in complex and dynamic system.
% Eigen grasp

%TODO: Problem need to solve in modular approach


%In robot grasping, modularity is also studied. In general, planning a grasp for a multifinger robot hand and a given object shape is a computational expansive task, especially for anthropomorphic robot hand with numerous number of joints. XXXXX~\ref{} proposed the concept of ``eigengrasp'' to simplify the grasp planning problem: three different preshapes of the hand are tested to grasp different objects. Approaching the object with a particular preshape until touching, the hand clutch around the object to form a grasp. XXXXX of objects are successfully grasped by one of the three preshapes. This modular approach reduce the complex grasp planning problem to a simple 3-class classification: one only need to classify with preshapes needs to be used for the target object and decide the approach direction.


