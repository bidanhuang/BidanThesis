\chapter{Learning human manipulation skill}
\label{cha4}
% Motivation - Methodology - Experiment - Result - Discussion

\section{Introduction}
\label{cha4:sec1}
% Motivation
% OM is important: what it can do? how it helps human?
In our daily life, object manipulation is one of the most commonly used skills. It includes a large category of activities ranging from the simple pick-and-place task to the complicated dexterous manipulation task, like writing or using chopsticks. Service robots won't be able to really ``serve'' humans without these manipulation abilities. Enabling robots to carry out manipulation tasks can alleviate human workload and free humans from many chores. However, robots with human level manipulation skills still only exist in science fiction.

% OM is difficult: why it is difficult?
Generally, manipulation tasks are very difficult for robots. Distinct from pure motion planning, manipulation planning aims to not only move the robot to a desire state, but also to change the environment to a desired state. Therefore in addition to robot motion planning, the impact of the robot on the environment, i.e. robot environment interaction, has to be planned. The object interactions are usually complex and hard to predict as they involve complicated contact situations, and the changing kinematics and dynamic properties of the environment. The complicated physics in object interactions make manipulation tasks difficult. The multi-body interactions and the effects of friction can cause abrupt changes in the environment. This makes the environment non-linear and non-stationary.

% What is solution to OM? - adaptive control. What is AC? Benefit of AC, but difficult to design.
Control methods depending on invariable 
\textcolor{red}{invariant, or unvarying but not invariable (you choose!)}
environmental parameters are not efficient for most manipulation tasks. Adaptive control methods, which focus on handling varying parameters and initial uncertainly, are required for manipulation. An adaptive control strategy is usually hard to design, especially when it involves a complex environment. This demands deep inside \textcolor{red}{knowledge of} the task and the kinematic and dynamic properties of the environment.

% learn AC from human demonstration: benefit...
To this end, we conduct a learning from human demonstration approach to gain an adaptive control strategy. This approach has two-fold benefits: Firstly, we do not need to analytically derive the the kinematic and dynamic properties of the environment in order to design the controller. Secondly, it provides a framework to easily program a robot with a task skill. With an increasing use of robots in daily life, more and more tasks will need to be programmed. Non-linear control methods are usually limited to narrow categories of tasks and hence need to be carried out task by task. It is impractical to pre-program all such object manipulation tasks manually. Learning from human demonstration enables even non-programmers to program robots to do various kinds of tasks quickly.

% what human do: prediction
Humans can perform these skilled tasks and adapt to the changes without difficulty. At the heart of this skill is prediction~\cite{flanagan2006control}. Studies from neuroscience suggest that humans develop internal models for motor control, to predict the future state of the environment. By comparing the predictive state with the actual sensory state, the internal models monitor the progression of the tasks and launch the corresponding motor corrections and motor reactions to adapt.

%To handle these situations, robots have to be equipped with a nonlinear and non-stationary control strategy, which is hard to design by analytical approaches.

% Conventional AC is difficult, use modular. benefit of modular
Inspired by this concept, we propose an approach to learn a human adaptive control strategy. This adaptive control strategy is encoded with a modular model, which allows fast adaption to non-linear and non-stationary systems. Each module includes a forward model for context estimation and an inverse model for motor command generation. From multiple human demonstrations, we extract a set of strategies, each of which is responsible for one specific task context. Using this method, we modularize the human adaptive control strategy. Internal models (a forward model and an inverse model) are learnt within each module with a representation that can be easily transferred to a robot. When a robot executes a similar task, the forward models estimate the context of the task and \textcolor{red}{once} ``contextized'' \textcolor{red}{'contextualised' would be better throughout I think} the inverse models \textcolor{red}{are able to} generate proper commands to drive the \textcolor{red}{robot}.
Each learned control strategy is weighted by the similarity of the current task context and its corresponding context. The optimal strategy is computed as the linear combination of the weighted commands of each strategy.

This approach does not require any prior knowledge of the kinematics nor dynamics of the system, nor is it restricted to a specific robot platform. The control strategy is learnt at the object level and hence can be transferred from human to robot directly.
This work contributes a framework to modularize human adaptive control strategies for manipulation tasks and to transfer the learned internal models to a robot. To verify our approach, we use a \emph{Opening Bottle Caps} task as an experiment. An adaptive control strategy is required here, as the friction between the bottle and the cap surfaces has multiple phases. We modularize the human control strategy in this task and implement it on a robot to open both familiar and novel bottles.

In the next few sections, I will present our approach of learning a multiple module model of a human manipulation strategy~\ref{cha4:sec1}, detail the experimental setups~\ref{cha4:sec2} and discuss the results~\ref{cha4:sec3}.

\input{includes/cha4_sec2_method}
\input{includes/cha4_sec3_experiment}
\input{includes/cha4_sec4_discussion}
