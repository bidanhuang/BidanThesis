\section{Grasping and manipulation by modular approaches}
\label{cha2:sec5:grasping-modular}

Modular approaches in robot grasping and manipulation to reduce the problem complexity. Modularization in grasping and manipulation are mainly done in two approaches: modularize by perception and modularize by action. Perceptual modules are mainly used in planning, while action modules are mainly used in execution.

\subsection{Modularize by perception}

The first step of making a plan of grasping and manipulation is observing the object. Most of grasp stability analysis are done based on the shape of an object. In human dominated environment, the possible shapes of objects to grasp and manipulate is infinite. Conventional methods to model these object are mostly effective in convex models~\citep{}. For highly non-convex shapes, local vision features such as edges and colors are used to generate grasping plans~\citep{}. To solve this problem, \citet{ } propose a modular approach, i.e. planning grasps by shape primitives. The key idea is to approximate a complex object, e.g. non-convex shape, to a set of shape primitives such as boxes, cylinders and spheres. Planning on these shape primitives is relatively easier or pre-trained. Therefore the complex planning problem is tamed to a set of simple problems. According to different purposes, different shape primitives are proposed. \citet{miller2003automatic} use four primitives including box, cone, cylinder and sphere; \citet{huebner2008minimum} use minimum bounding box to decompose an object and \citet{el2010new} use superquadric as the shape primitive. These methods are based on the complete object point clouds, which may not be fully accessible in the real scenario. Methods to split objects to shape primitives and detect primitives parts are proposed, which mainly exploit the techniques in graphics such as the RANdom SAmple Consensus (RANSAC)~\citet{}.
\citet{faria2012extracting} use multiple sensors to track human hand trajectory and tactile data, and hence extract motion primitives and contact primitives from the demonstration. These information is then merged to form a object probabilistic volumetric model, which is decomposed to multiple superquadrics.

\subsection{Modularize by action}
The motion primitive concept is also introduced to grasping and manipulation. Different from the reaching movement primitives discussed in the previous Section~\ref{cha2:sec3:modular:robotics}, of which the goals are to reach the targeted points, the grasping and manipulation motion primitives are more task-oriented, i.e. each primitive is associated with a specific impact on the environment, such as getting contact with the object and pushing the object. Therefore in literatures these primitives are sometimes referred to ``task primitives''. In early studies, these task primitives are manually defined, transitions between them are decided by contact events that indicate the impacts on the environment. Relationship between these primitives are represented by finite state machines~\citep{ }. Later the Dynamical Movement Primitives (DMP) mentioned previously, which models desired motion by an attractor landscape, is extended to due with various problems executing a grasp. The combination of the DMP and the Early Cognitive Vision Descriptor (ECVD) for grasp planning enable a robot to plan approaching path of the hand and the finger that avoids pre-mature contact between finger and object~\citep{ }. Taking the possible poses of an object into account, the optimization of DMP is able to form approaching trajectories that maximise the robust of the grasps~\citep{ }. Later simplify version of DMP is used to learn movement goal and hence can quickly change the end point location to adapt the object shape~\citep{ }.

Besides DMP, other grasping and manipulation primitives are proposed to handel different problems in this discipline. \citet{ } propose a hierarchical approach to solve the embodiment problem of sharing experience within different robot platforms. This is done by defining an abstract manipulation primitive layer and an embodiment layer. The translation from the abstract layer to the embodiment layer enable the robot to plan tasks in the higher layer, while execute it by low level control. \citet{ } use a compliant force grasp primitive to grasp small object from a table top. To facilitate manipulation motion planning, \citet{ } use a Rapidly exploring Random Tree (RRT) to sequence motion primitives.

\paragraph{Synergy}
\label{cha2:sec5:grasping-modular:synergy}
Further, the concept of synergy originating in the neurophysiological studies is also introduced into the field of robotics to tame the complexity of robot grasping~\ref{}. In this field of study, roboticists try to understand how does human central neural system (CNS) simplify the grasping strategy and how to mimic this mechanism in robot system. This involve not only the studies of the redundancy in human hand mobility but also the redundancy in human cutaneous and kinaesthetic perception. With the recent rapid development of tactile sensors, robots are equipped with more delicate tactile perception. How collect sensation information from these tactile receptors is also a hot topic in robot synergy. In once word, the study of robot sensorimotor synergies aim to find out the modularity in human muscles, joints, fingers, receptors so as to enable robot working in complex and dynamic system.

%TODO: Grasp by shape primitives



%TODO: Problem need to solve in modular approach

% Eigen grasp
Instead of directly searching the high dimensional configuration space of robotic hands, this space can be reduced by generating a set of grasp starting positions, hand preshapes~\cite{Miller03} or eigengrasps~\cite{Ciocarlie09} that can then be tested on the object model. Such approaches reduce the dimensionality of the hand configuration space, but doing so implies a corresponding reduction in the accessible hand postures.


In robot grasping, modularity is also studied. In general, planning a grasp for a multifinger robot hand and a given object shape is a computational expansive task, especially for anthropomorphic robot hand with numerous number of joints. XXXXX~\ref{} proposed the concept of ``eigengrasp'' to simplify the grasp planning problem: three different preshapes of the hand are tested to grasp different objects. Approaching the object with a particular preshape until touching, the hand clutch around the object to form a grasp. XXXXX of objects are successfully grasped by one of the three preshapes. This modular approach reduce the complex grasp planning problem to a simple 3-class classification: one only need to classify with preshapes needs to be used for the target object and decide the approach direction.
