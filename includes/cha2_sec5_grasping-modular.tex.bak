\section{Grasping and manipulation by modular approaches}
\label{cha2:sec5:grasping-modular}

Modular approaches in robot grasping and manipulation to reduce the problem complexity. Modularization in grasping and manipulation are mainly done in two approaches: modularize by perception and modularize by action. Perceptual modules are mainly used in planning, while action modules are mainly used in execution.

\subsection{Modularize by perception}

The first step of making a plan of grasping and manipulation is observing the object. Most of grasp stability analysis are done based on the shape of an object. In human dominated environment, the possible shapes of objects to grasp and manipulate is infinite. Conventional methods to model these object are mostly effective in convex models~\citep{}. For highly non-convex shapes, local vision features such as edges and colors are used to generate grasping plans~\citep{}. To solve this problem, \citet{ } propose a modular approach, i.e. planning grasps by shape primitives. The key idea is to approximate a complex object, e.g. non-convex shape, to a set of shape primitives such as boxes, cylinders and spheres. Planning on these shape primitives is relatively easier or pre-trained. Therefore the complex planning problem is tamed to a set of simple problems. According to different purposes, different shape primitives are proposed. \citet{miller2003automatic} use four primitives including box, cone, cylinder and sphere; \citet{huebner2008minimum} use minimum bounding box to decompose an object and \citet{el2010new} use superquadric as the shape primitive. These methods are based on the complete object point clouds, which may not be fully accessible in the real scenario. Methods to split objects to shape primitives and detect primitives parts are proposed, which mainly exploit the techniques in graphics such as the RANdom SAmple Consensus (RANSAC)~\citet{}.
\citet{faria2012extracting} use multiple sensors to track human hand trajectory and tactile data, and hence extract motion primitives and contact primitives from the demonstration. These information is then merged to form a object probabilistic volumetric model, which is decomposed to multiple superquadrics.

\subsection{Modularize by action}
The motion primitive concept is also introduced to grasping and manipulation. Different from the reaching movement primitives discussed in the previous Section~\ref{cha2:sec3:modular:robotics}, of which the goals are to reach the targeted points, the grasping and manipulation motion primitives are more task-oriented, i.e. each primitive is associated with a specific impact on the environment, such as getting contact with the object and pushing the object. Therefore in literatures these primitives are sometimes referred to ``task primitives''. Because of the variety of tasks and their complexity, usually these task primitives are manually defined. Transitions between them are usually decided by contact events that indicate the impacts on the environment~\citep{morrow1997manipulation}. \citet{michelman1994forming} propose to represent the relationship between task primitives by a finite state machines. \citet{kazemi2012robust} define three task primitives for force compliant grasping of small objects from a table top. The Dynamical Movement Primitives (DMP) mentioned previously, which models desired motion by an attractor landscape, is extended to due with various problems when executing a grasp. The combination of the DMP and the Early Cognitive Vision Descriptor (ECVD) for grasp planning enable a robot to plan approaching path of the hand and the finger that avoids pre-mature contact between finger and object~\citep{kroemer2011grasping}. Taking the object poses distribution into account, a new optimization method of the DMP is proposed to find an approaching trajectory that produce robust grasp to object pose uncertainty~\citep{stulp2011learning}. Later simplify version of DMP is used to learn movement goal and hence can quickly change the end point location to adapt to the object shape~\citep{stulp2011learning,stulp2012reinforcement}.

A few frameworks are proposed to model and organize the task primitives. \citet{laaksonen2010embodiment,felip2013manipulation} propose a hierarchical framework to solve the embodiment problem of sharing experience among different robot platforms. This is done by defining task primitives in an abstract layer and an embodiment layer. The former can be translated to the later. This enable the robot to plan tasks with the higher level abstract primitives, while execute it by the embodiment specific task primitives. To facilitate manipulation motion planning, \citet{barry2013manipulation} use a Rapidly exploring Random Tree (RRT) to sequence motion primitives. \citet{detry2013generalizing} modularize a grasp planning task by two constraints: gripper constraints and task constraints. While the former module handle grasp stability, the later module select grasps by the task requirements. 

Besides task-specific motion primitives, modular approaches are also used to tame the complex grasp planning problem. The concept of ``hand synergies'', for example, is a modular approach originating in the neurophysiological studies~\citep{santello1998postural,santello2000force}. In this field of study, roboticists try to understand how does human central neural system (CNS) simplify the grasping strategy and how to mimic this mechanism in robot system. This concept is used in grip force control \citep{gabiccini2011role} as well as grasp planning \citep{gioioso2013mapping}. Similar to this idea, robot ``Eigen grasp'' is proposed to study the modularity in robot embodiment. Instead of directly searching good grasps the high dimensional configuration space of robotic hands, this space can be reduced by generating a set of grasp starting positions, hand preshapes~\cite{miller2003automatic} or eigengrasps~\cite{Ciocarlie2009} that can then be tested on the object model. Such approaches reduce the dimensionality of the hand configuration space, but doing so implies a corresponding reduction in the accessible hand postures.
%This involve not only the studies of the redundancy in human hand mobility but also the redundancy in human cutaneous and kinaesthetic perception. With the recent rapid development of tactile sensors, robots are equipped with more delicate tactile perception. How collect sensation information from these tactile receptors is also a hot topic in robot synergies. In once word, the study of robot sensorimotor synergies aim to find out the modularity in human muscles, joints, fingers, receptors so as to enable robot working in complex and dynamic system.
% Eigen grasp

%TODO: Problem need to solve in modular approach


%In robot grasping, modularity is also studied. In general, planning a grasp for a multifinger robot hand and a given object shape is a computational expansive task, especially for anthropomorphic robot hand with numerous number of joints. XXXXX~\ref{} proposed the concept of ``eigengrasp'' to simplify the grasp planning problem: three different preshapes of the hand are tested to grasp different objects. Approaching the object with a particular preshape until touching, the hand clutch around the object to form a grasp. XXXXX of objects are successfully grasped by one of the three preshapes. This modular approach reduce the complex grasp planning problem to a simple 3-class classification: one only need to classify with preshapes needs to be used for the target object and decide the approach direction.
